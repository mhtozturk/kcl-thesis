import re
import requests
import unicodedata
import pandas as pd
from bs4 import BeautifulSoup

class EDGAR:
    """
    Class for gathering, processing, and preparing SEC Filing data obtained via
    SEC EDGAR API.
    """
    # agent for access
    AGENT = {'User-Agent': 'mehmet.ozturk@kcl.ac.uk'}
    # formatting patterns
    # regex for formatting
    NEGATIVE = re.compile(r'[(),]')
    POSITIVE = re.compile(r',')
    # income statement terms
    IS_TERMS = {
        'revenue': ['revenue', 'total revenue', 'net sale', 'total net sales', 
                    'total revenues', 'net sales', 'net revenue'],
        'gross profit': ['gross profit', 'gross margin'],
        'operating income': ['operating income', 'income from operations', 'loss from operations', 
                             'income (loss) from operations', 'operating income (loss)'],
        'net income': ['net income', 'net income (loss)', 'net loss'],
        'eps': ['basic', 'basic earnings per share', 'basic net income per share']
    }
    # balance sheet terms
    BS_TERMS = {
        'cash' : ['cash and cash equivalents'],
        'current assets': ['total current assets', 'total current assets'],
        'current liabilities': ['total current liabilities', 'total current liabilities'],
        'shareholder equity': ['total stockholders’ equity', 'total shareholders’ equity', 'total equity', 
                               'total shareholders\' equity', 'total stockholders\' equity']
    }
    # cash flow statement terms
    CFS_TERMS = {
        'net cash operating': ['net cash provided by operating activities', 'cash generated by operating activities', 
                               'net cash provided by (used in) operating activities', 'net cash used in operating activities'],
        'net cash investing': ['cash generated by/(used in) investing activities', 
                               'net cash provided by (used in) investing activities', 
                               'net cash used in investing activities', 'cash used in investing activities',
                               'net cash used for investing activities', 'cash generated by investing activities',
                               'net cash provided by investing activities', 
                               'net cash provided by (used for) investing activities'],
        'net cash financing': ['cash used in financing activities', 'net cash used in financing activities',
                               'net cash provided by (used in) financing activities', 
                               'net cash provided by financing activities', 
                               'net cash used for financing activities', 
                               'net cash (used in) provided by financing activities', 
                               'net cash used in by financing activities'],
    }
    # forward-looking words obtained from different filings
    FORWARD_LOOKING_WORDS = ['anticipate', 'anticipates', 'believe', 'believes', 'could', 'designed', 
                             'estimate', 'estimates', 'expect', 'expects', 'future', 'goal', 'intend',
                             'intends', 'may', 'opportunity', 'plan', 'plans', 'potential', 'predict', 
                             'predicts', 'project', 'seeks', 'should', 'will', 'would']
    # forward-looking words
    FLS = re.compile(r'\b(' + '|'.join(map(re.escape, FORWARD_LOOKING_WORDS)) + r')\b', re.IGNORECASE)

    def __init__(self, ticker: str, ciks: pd.DataFrame) -> None:
        """Method for initialising object.

        ticker: Company's symbol
        ciks: DataFrame of CIKs obtained via <https://www.sec.gov/files/company_tickers.json>
        """
        # central index key (CIK)
        self.cik = ciks.loc[ciks['ticker'] == ticker, 'cik_str'].iat[0]
        # metadata
        self.metadata = None
        # master dictionary for SEC data
        self.sec_data = {}

    def get_metadata(self, start_date: str | pd.Timestamp = '2017-01-01', end_date: str | pd.Timestamp = '2024-01-01') -> None:
        """Method for getting the company's submission history after the given year's 
        annual filing and filtering for remaining quarterly and annual filings.
        
        start_date: Date in the form [YYYY-MM_DD]
        end_date: Date in the form [YYYY-MM_DD]
        """
        # date transformation
        if type(start_date) == str:
            start_date = pd.to_datetime(start_date)

        if type(end_date) == str:
            end_date = pd.to_datetime(end_date)

        # accessing EDGAR API for submissions history
        metadata = requests.get(
            f'https://data.sec.gov/submissions/CIK{self.cik.zfill(10)}.json',
            headers = EDGAR.AGENT
        )
        # request success check
        if metadata.status_code == 200:
            print(f'Respone: [{metadata.status_code}], metadata obtained successfully.')
        else:
            print(f'Response: [{metadata.status_code}], couldn\'t obtain metadata.')
            return

        # filtering submissions
        metadata = pd.DataFrame.from_dict(metadata.json()['filings']['recent'])
        metadata['reportDate'] = pd.to_datetime(metadata['reportDate'])
        metadata['filingDate'] = pd.to_datetime(metadata['filingDate'])

        # starting year's annual filing's date
        date = metadata[(metadata['form'] == '10-K') & (metadata['reportDate'].dt.year == start_date.year)]['filingDate'].iloc[0]
        metadata = metadata[metadata['filingDate'] > date]
        metadata = metadata[metadata['filingDate'] < pd.to_datetime(f"{end_date}")]

        # filtering for 10-K and 10-Q
        metadata = metadata[metadata['form'].isin(['10-K', '10-Q'])].reset_index(drop=True)
        self.metadata = metadata.sort_index(ascending=False).reset_index(drop=True)

    def process_filings(self, accession_number: str, quarter: int, year: bool = False) -> None:
        """Method for processing filings.
        
        accession_number: Unique access number for accessing filing
        quarter: Quarter of the filing (annual filings are treated as fourth quarter)
        year: True for 10-K and False for 10-Q
        """
        # master dictionary for filing data
        data = {}
        # previous dates used for cash flows calculations
        prev_quarters = list(self.sec_data.keys())[-(quarter - 1):] if quarter != 1 else None
        # found (DEBUGGING)
        found = False

        # accessing EDGAR API for filing source file
        filing = requests.get(
            f'https://www.sec.gov/Archives/edgar/data/{self.cik}/{accession_number.replace("-", "")}/{accession_number}.txt',
            headers = EDGAR.AGENT
        )
        # request success check
        if filing.status_code == 200:
            print(f'Respone: [{filing.status_code}], filing obtained successfully.')
        else:
            print(f'Response: [{filing.status_code}], couldn\'t obtain filing.')
            return

        # parsing file with BeautifulSoup
        soup = BeautifulSoup(filing.content, 'lxml')
        # extracting form
        form = soup.find('document')
        form_str = str(form)

        # DEBUGGING: filename
        name = form.filename.find(text = True, recursive = False).strip()
        print(f"Current filename:\t {name}")

        # splitting into seperate pages for easier parsing
        # <hr> tag is used consistently in filings for page breaks
        hr_breaks = form.find_all(lambda tag: tag.name == 'hr' and 'page-break-after:always' in tag.get('style', ''))
        # transforming into string objects for regex
        hr_breaks = [str(hr) for hr in hr_breaks]
        # creating regular expression for splitting pages
        hr_regex = '|'.join(map(re.escape, hr_breaks))

        form_pages = re.split(hr_regex, form_str)

        for index, page in enumerate(form_pages):
            page_soup = BeautifulSoup(page, 'html5lib')

            # multiplier
            multiplier = 1000

            # parsing income statement
            if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') 
                               and 'text-align:center' in tag.get('style', '')
                               and any(term in tag.get_text(strip=True).lower() for term in ['income', 'operations', 'earnings'])
                               and 'statements' in tag.get_text(strip=True).lower()
                               and 'comprehensive' not in tag.get_text(strip=True).lower() 
                               and tag.find('table') == None):
                # DEBUGGING
                # print(f"Income Statement: {index}")

                # finding the multiplier
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p')
                                  and 'text-align:center' in tag.get('style', '')
                                  and 'millions' in tag.get_text(strip=True).lower()):
                    multiplier = 1000000
                
                # DEBUGGING
                # print(f"Multiplier: {multiplier}")

                # finding the table
                table = page_soup.find(lambda tag: tag.name == 'table'
                                       and 'width' in tag.get('style', '')
                                       and float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 89)
                
                # success check
                if table == None:
                    print("No table found.")
                    continue
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting row elements
                    cells = [td.get_text(strip=True).lower() for td in row.find_all('td')
                             if td.get_text(strip=True) != '$' and td.get_text(strip=True) != '']
                    # at least 2 elements
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print(f"Row: {cells}")

                    # keyword name
                    key = cells[0]
                    # DEBUGGING
                    # print(f"Key: {key}")

                    # extracting relevant terms
                    for term, variations in EDGAR.IS_TERMS.items():
                        if key in variations:
                            if term not in data.keys():
                                try:
                                    # first value is most recent
                                    value = cells[1]
                                    if quarter == 4:
                                        # if annual, sum of previous quarters subtracted from annual aggregate
                                        prev_value = sum([self.sec_data[date][term] for date in prev_quarters])
                                    else:
                                        # first value is most recent
                                        prev_value = 0
                                    # formatting value
                                    if '(' in value:
                                        value = -float(EDGAR.NEGATIVE.sub('', value))
                                        if term == 'eps':
                                            data[term] = value - prev_value
                                        else:
                                            data[term] = (value * multiplier) - prev_value
                                    else:
                                        value = float(EDGAR.POSITIVE.sub('', value))
                                        if term == 'eps':
                                            data[term] = value - prev_value
                                        else:
                                            data[term] = (value * multiplier) - prev_value
                                except:
                                    data[term] = None

            # parsing balance sheet
            elif page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') 
                               and 'text-align:center' in tag.get('style', '')
                               and 'balance sheets' in tag.get_text(strip=True).lower()
                               and tag.find('table') == None):
                # DEBUGGING
                print(f"Balance Sheet: {index}")

                # finding the multiplier
                if page_soup.find(lambda tag: ((tag.name == 'div' or tag.name == 'p')
                                  and 'text-align:center' in tag.get('style', '')
                                  and 'millions' in tag.get_text(strip=True).lower())
                                  or (tag.name == 'span' 
                                      and 'millions' in tag.get_text(strip=True).lower())):
                    multiplier = 1000000
                
                # DEBUGGING
                print(f"Multiplier: {multiplier}")

                # finding the table
                table = page_soup.find(lambda tag: tag.name == 'table'
                                       and 'width' in tag.get('style', '')
                                       and float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 89)
                
                # success check
                if table == None:
                    print("No table found.")
                    continue
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting row elements
                    cells = [td.get_text(strip=True).lower() for td in row.find_all('td')
                             if td.get_text(strip=True) != '$' and td.get_text(strip=True) != '']
                    # at least 2 elements
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print(f"Row: {cells}")

                    # keyword name
                    key = cells[0]
                    # DEBUGGING
                    # print(f"Key: {key}")

                    # extracting relevant terms
                    for term, variations in EDGAR.BS_TERMS.items():
                        if key in variations:
                            if term not in data.keys():
                                try:
                                    # first value is most recent
                                    value = cells[1]
                                    # formatting value
                                    if '(' in value:
                                        value = -float(EDGAR.NEGATIVE.sub('', value))
                                        data[term] = value * multiplier
                                    else:
                                        value = float(EDGAR.POSITIVE.sub('', value))
                                        data[term] = value * multiplier
                                except:
                                    data[term] = None

            # parsing cash flow statement
            elif page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') 
                               and 'text-align:center' in tag.get('style', '')
                               and 'cash flows' in tag.get_text(strip=True).lower()
                               and tag.find('table') == None):
                # DEBUGGING
                # print(f"Cash Flow Statement: {index}")

                # finding the multiplier
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p')
                                  and 'text-align:center' in tag.get('style', '')
                                  and 'millions' in tag.get_text(strip=True).lower()):
                    multiplier = 1000000
                
                # DEBUGGING
                # print(f"Multiplier: {multiplier}")

                # finding the table
                table = page_soup.find(lambda tag: tag.name == 'table'
                                       and 'width' in tag.get('style', '')
                                       and float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 89)
                
                # success check
                if table == None:
                    print("No table found.")
                    continue
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting row elements
                    cells = [td.get_text(strip=True).lower() for td in row.find_all('td')
                             if td.get_text(strip=True) != '$' and td.get_text(strip=True) != '']
                    # at least 2 elements
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print(f"Row: {cells}")

                    # keyword name
                    key = cells[0]
                    # DEBUGGING
                    # print(f"Key: {key}")

                    # extracting relevant terms
                    for term, variations in EDGAR.CFS_TERMS.items():
                        if key in variations:
                            # DEBUGGING
                            # print(f"Term: {term}")
                            if term not in data.keys():
                                try:
                                    # first value is most recent
                                    value = cells[1]
                                    # summing previous quarters
                                    if quarter == 1:
                                        prev_value = 0
                                    else:
                                        prev_value = sum([self.sec_data[date][term] for date in prev_quarters])
                                    # formatting value
                                    if '(' in value:
                                        value = -float(EDGAR.NEGATIVE.sub('', value))
                                        data[term] = (value * multiplier) - prev_value
                                    else:
                                        value = float(EDGAR.POSITIVE.sub('', value))
                                        data[term] = (value * multiplier) - prev_value
                                except:
                                    data[term] = None

            # MD&A start page index
            elif page_soup.find(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p')
                                and 'discussion and analysis of financial condition' in tag.get_text(strip=True).lower()
                                and 'font-weight' in tag.get('style', '') 
                                and tag.find('table') == None
                                and index > 1
                                and found == False):
                # DEBUGGING
                # print(f"MD&A Start: {index}")
                # saving index
                start_index = index
                found = True
                
            # MD&A end page index
            elif page_soup.find(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p')
                                and ('quantitative and qualitative disclosure about market risk' in tag.get_text(strip=True).lower()
                                     or 'quantitative and qualitative disclosures about market risk' in tag.get_text(strip=True).lower())
                                and 'font-weight' in tag.get('style', '') 
                                and tag.find('table') == None
                                and index > 1):
                # DEBUGGING
                # print(f"MD&A End: {index}")
                # saving index
                end_index = index

            else:
                continue

        # extracting forward-looking statements
        data['statements'] = self.process_mda(pages=form_pages[start_index:end_index])
        # DEBUGGING
        # print(f"Statements: {data['statements']}")
        
        return data
    
    def process_mda(self, pages: list) -> list:
        """Method for processing the Management's Discussion and Analysis (MD&A) pages
        and extracting forward-looking statements' for sentiment analysis.

        pages: The pages that belong to MD&A
        """
        # list for storing statements
        fls = []

        for page in pages:
            page_soup = BeautifulSoup(page, 'html5lib')
            # getting code for all <div> and <p> tags where target words are seen
            paragraph = [paragraph for paragraph in page_soup.find_all(lambda tag: tag.name == 'div' or tag.name == 'p')
                          if EDGAR.FLS.search(paragraph.get_text(strip=False).lower())]
            
            # extracting paragraphs and normalising
            normalised = []
            for paragraph in paragraph:
                # paragraphs with 'italic' style can be disregarded
                if paragraph.name == 'div':
                    italic = False
                    for tag in paragraph.find_all(lambda tag: tag.name == 'font' or tag.name == 'span'):
                        if 'italic' in tag.get('style', ''):
                            italic = True
                            break
                    
                    if italic == True:
                        continue
                    else:
                        # normalising text
                        normalised.append(unicodedata.normalize('NFKC', paragraph.get_text(strip=False).lower()).replace('  ', ' '))

                else:
                    if 'italic' in paragraph.get('style', ''):
                        continue
                    else:
                        # normalising text
                        normalised.append(unicodedata.normalize('NFKC', paragraph.get_text(strip=False).lower()).replace('  ', ' '))

            for paragraph in normalised:
                # seperating into sentences
                sentences = re.split(r'(?<=[.!?]) +', paragraph)
                text = ""

                for sentence in sentences:
                    # checking if forward-looking statement
                    if EDGAR.FLS.search(sentence):
                        text += sentence + " "
                    else:
                        continue

                if text != "":
                    fls.append(text)

        return fls

    def run(self, start_date: str | pd.Timestamp = '2017-01-01', end_date: str | pd.Timestamp = '2024-01-01') -> None:
        """Method for properly running other methods.

        start_date: Date in the form [YYYY-MM-DD], the processing starts after the 10-K with filing year of start_year
        end_date: Date in the form [YYYY-MM-DD], the processing ends with the filing closest to end_date
        """
        self.get_metadata(start_date=start_date, end_date=end_date)

        # process filings
        # for idx in range(4):
        for idx in range(len(self.metadata)):
            filing = self.metadata.iloc[idx]

            if filing['form'] == '10-K':
                self.sec_data[filing['filingDate']] = self.process_filings(filing['accessionNumber'], quarter=4, year=True)
            else:
                self.sec_data[filing['filingDate']] = self.process_filings(filing['accessionNumber'], quarter=(idx % 4 + 1))
