import re
import requests
import pandas as pd
import unicodedata
from bs4 import BeautifulSoup

class Data:
    """
    Class for gathering, processing, and preparing SEC Filing data obtained via
    SEC EDGAR API.
    """
    # CONSTANTS:
    # agent for accessing API
    AGENT = {'User-Agent': 'mehmet.ozturk@kcl.ac.uk'}
    # operations/income/earnings statement target terms
    OIE_TERMS = {
        'revenue': ['revenue', 'total revenue', 'net sale', 'total net sales', 'total revenues', 'net sales'],
        'gross profit': ['gross profit', 'gross margin'],
        'operating income': ['operating income', 'income from operations', 'loss from operations',
                             'income (loss) from operations'],
        'net income': ['net income', 'net income (loss)', 'net loss'],
        'eps': ['basic', 'basic earnings per share', 'basic net income per share']}
    # balance sheet target terms
    BS_TERMS = {
        'current assets': ['total current assets', 'total current assets'],
        'current liabilities': ['total current liabilities', 'total current liabilities'],
        'shareholder equity': ['total stockholders’ equity', 'total shareholders’ equity', 'total equity',
                               'total shareholders\' equity', 'total stockholders\' equity']}
    # cash flow statement target terms
    CF_TERMS = {
        'net cash operating': ['net cash provided by operating activities', 'cash generated by operating activities', 
                               'net cash provided by (used in) operating activities', 'net cash used in operating activities'],
        'net cash investing': ['cash generated by/(used in) investing activities', 
                               'net cash provided by (used in) investing activities', 
                               'net cash used in investing activities', 'cash used in investing activities',
                               'net cash used for investing activities', 'cash generated by investing activities',
                               'net cash provided by investing activities',
                               'net cash provided by (used for) investing activities'],
        'net cash financing': ['cash used in financing activities', 'net cash used in financing activities',
                               'net cash provided by (used in) financing activities',
                               'net cash provided by financing activities', 'net cash used for financing activities',
                               'net cash (used in) provided by financing activities'],
        'cash': ['cash and cash equivalents at end of period', 'cash and cash equivalents, end of period', 
                 'cash, cash equivalents and restricted cash, ending balances',
                 'cash and cash equivalents and restricted cash, end of period', 
                 'cash and cash equivalents, end of the period', 
                 'cash, cash equivalents, and restricted cash at end of the period',
                 'cash, cash equivalents, and restricted cash at end of period', 'cash and cash equivalents, ending balances',
                 'cash and cash equivalents at end of year', 'cash and cash equivalents, end of the year',
                 'cash, cash equivalents, and restricted cash at end of year']}
    # forward-looking words obtained from different filings
    FORWARD_LOOKING_WORDS = ['anticipate', 'anticipates', 'believe', 'believes', 'could', 'designed', 
                             'estimate', 'estimates', 'expect', 'expects', 'future', 'goal', 'intend',
                             'intends', 'may', 'opportunity', 'plan', 'plans', 'potential', 'predict', 
                             'predicts', 'project', 'seeks', 'should', 'will', 'would']
    # keywords for important financial context
    CONTEXT_WORDS = ['revenue', 'revenues', 'profit', 'profits', 'growth', 'market', 'performance', 'financial', 
                     'result', 'results', 'sale', 'sales', 'income', 'earnings', 'expense', 'expenses', 'cost', 
                     'costs', 'investment', 'investments', 'debt', 'debts', 'equity', 'equities', 'asset', 
                     'assets', 'liability', 'liabilities', 'cash flow', 'cash flows', 'margin', 'margins', 
                     'return', 'returns', 'valuation', 'capital', 'operations']
    # regex for formatting
    NEGATIVE_PATTERN = re.compile(r'[(),]')
    POSITIVE_PATTERN = re.compile(r',')
    # regex for NLP
    # forward looking statement search pattern
    PATTERN = re.compile(r'\b(' + '|'.join(map(re.escape, FORWARD_LOOKING_WORDS)) + r')\b', re.IGNORECASE)
    # important context pattern
    CONTEXT = re.compile(r'\b(' + '|'.join(map(re.escape, CONTEXT_WORDS)) + r')\b', re.IGNORECASE)

    def __init__(self, ticker: str):
        # used to obtain CIK (central index key)
        self.ticker = ticker
        # used to obtain metadata
        self.cik = None
        # used to store data
        self.data = {}
        # metadata
        self.metadata = None

    def get_cik(self, df: pd.DataFrame) -> None:
        """Method for getting the CIK of a company.

        :param df: DataFrame of CIKs obtained via <https://www.sec.gov/files/company_tickers.json>.
        """
        self.cik = df.loc[df['ticker'] == self.ticker, 'cik_str'].iat[0]

    def get_metadata(self) -> None:
        """Method for getting the SEC filings metadata of a company.
        """
        # API for the metadata of all filings
        metadata = requests.get(
            f'https://data.sec.gov/submissions/CIK{self.cik.zfill(10)}.json',
            headers = Data.AGENT
        )
        # request check
        if metadata.status_code == 200:
            print(f'Respone: [{metadata.status_code}], metadata obtained successfully.')
        else:
            print(f'Response: [{metadata.status_code}], couldn\'t obtain metadata.')
            return
        
        # filtering out all filings except [10-Q] and [10-K]
        self.metadata = pd.DataFrame.from_dict(metadata.json()['filings']['recent'])
        self.metadata = self.metadata[self.metadata['form'].isin(['10-K', '10-Q'])].reset_index(drop=True)
        self.metadata = self.metadata.sort_index(ascending=False).reset_index(drop=True)

        # DEBUGGING
        # print(self.metadata)
        # storing all filings after 2017 [10-K] as the source codes became more consistent
        self.metadata['reportDate'] = pd.to_datetime(self.metadata['reportDate'])
        # finding the date of the [10-K] form in 2017
        date = self.metadata[(self.metadata['form'] == '10-K') & (self.metadata['reportDate'].dt.year == 2017)]['reportDate'].iloc[0]
        self.metadata = self.metadata[self.metadata['reportDate'] > date]

    def process_quarterly(self, accession_number: str, quarter: int) -> dict:
        """Method for processing quarterly [10-Q] filings.

        :param accession_number: Unique access number for each filing.
        :rtype: Dictionary.
        """
        # accessing the [.txt] file that contains all HTML source code for a filing
        filing = requests.get(
            f'https://www.sec.gov/Archives/edgar/data/{self.cik}/{accession_number.replace("-", "")}/{accession_number}.txt',
            headers = Data.AGENT
        )
        # request check
        if filing.status_code == 200:
            print(f'Respone: [{filing.status_code}], filing obtained successfully.')
        else:
            print(f'Response: [{filing.status_code}], couldn\'t obtain filing.')
            return
        
        # initialising dictionary for storing data (features)
        data = {}

        # parsing filing with BeautifulSoup
        soup = BeautifulSoup(filing.content, 'lxml')
        # extracting [10-Q] form
        form = soup.find('document')
        # DEBUGGING: printing out file's name for easy access if needed
        name = form.filename.find(text = True, recursive = False).strip()
        print(f"Current filename:\t {name}")

        # splitting into seperate pages for easier parsing
        # <hr> tag is used consistently in filings for page breaks
        hr_breaks = form.find_all(lambda tag: tag.name == 'hr' and 'page-break-after:always' in tag.get('style', ''))
        # transforming into string objects for regex
        hr_breaks = [str(hr) for hr in hr_breaks]
        form_str = str(form)
        # creating regular expression for splitting pages
        hr_regex = '|'.join(map(re.escape, hr_breaks))
        
        form_pages = re.split(hr_regex, form_str)

        # previous dates used for cash flows calculations
        prev = list(self.data.keys())[-(quarter-1):] if quarter != 1 else None

        # multiplier
        multiplier = 1

        # getting numerical data
        for index, page in enumerate(form_pages):
            page_soup = BeautifulSoup(page, 'html5lib')

            # operations/income/earnings statement (page)
            if ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                           any(term in tag.get_text(strip = True).lower() for term in ['income', 'operations', 'earnings'])
                           and 'statements' in tag.get_text(strip = True).lower()
                           and 'comprehensive' not in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                           any(term in tag.get_text(strip = True).lower() for term in ['income', 'operations', 'earnings'])
                           and 'statements' in tag.get_text(strip = True).lower()
                           and 'comprehensive' not in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("OIE page found:", index)

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the statement
                table = page_soup.find(lambda tag: tag.name == 'table' and 'width' in tag.get('style', '') and
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 89)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("OIE table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.OIE_TERMS.items():
                        if key in variations:
                            if term not in data.keys():
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        if term == 'eps':
                                            data[term] = value
                                        else:
                                            data[term] = round(value / multiplier)
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        if term == 'eps':
                                            data[term] = value
                                        else:
                                            data[term] = round(value / multiplier)
                                except:
                                    data[term] = None

            # balance sheet (page)
            elif ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                            'balance sheets' in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                            'balance sheets' in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("BS page found")

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the balance sheet
                table = page_soup.find(lambda tag: tag.name == 'table' and 
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 90)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("BS table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.BS_TERMS.items():
                        if key in variations:  
                            if term not in data.keys():
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier)
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier)
                                except:
                                    data[term] = None

            # cash flows statement (page)
            elif ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                            'cash flows' in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                            'cash flows' in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("CF page found", index)

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the statement
                table = page_soup.find(lambda tag: tag.name == 'table' and 
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 90)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("CF table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.CF_TERMS.items():
                        if key in variations: 
                            if term not in data.keys():
                                prev_value = sum([self.data[date][term] for date in prev]) if term != 'cash' and prev != None else 0
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        
                                        data[term] = round(value / multiplier) - prev_value
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier) - prev_value
                                except:
                                    data[term] = None

            # getting M.D.&A. initial page index
            elif (page_soup.find_all(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p') and 
                                     'discussion and analysis of financial condition and results' in tag.get_text(strip = True).lower()
                                     and tag.find('table') == None and 'font-weight' in tag.get('style', '') and index > 1)):
                # DEBUGGING
                # print("Found M.D.&A. initial page index")
                # saving the index
                start_index = index

            # getting M.D.&A. final page index
            elif (page_soup.find_all(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p') and 
                                     'quantitative and qualitative disclosures about market risk' in tag.get_text(strip = True).lower()
                                     and tag.find('table') == None and 'font-weight' in tag.get('style', '') and index > 1)):
                # DEBUGGING
                # print("Found M.D.&A. final page index")
                # saving the index
                end_index = index

            else:
                continue

        # extracting forward-looking statements
        # data['statements'] = self.process_mda(form_pages[start_index:end_index])
        # print(self.process_mda(form_pages[start_index:end_index]))  

        return data

    def process_annual(self, accession_number: str) -> dict:
        """Method for processing annual [10-K] filings.

        :param accession_number: Unique access number for each filing.
        :rtype: Dictionary.
        """
        # accessing the [.txt] file that contains all HTML source code for a filing
        filing = requests.get(
            f'https://www.sec.gov/Archives/edgar/data/{self.cik}/{accession_number.replace("-", "")}/{accession_number}.txt',
            headers = Data.AGENT
        )
        # request check
        if filing.status_code == 200:
            print(f'Respone: [{filing.status_code}], filing obtained successfully.')
        else:
            print(f'Response: [{filing.status_code}], couldn\'t obtain filing.')
            return
        
        # initialising dictionary for storing data (features)
        data = {}

        # parsing filing with BeautifulSoup
        soup = BeautifulSoup(filing.content, 'lxml')
        # extracting [10-K] form
        form = soup.find('document')
        # DEBUGGING: printing out file's name for easy access if needed
        name = form.filename.find(text = True, recursive = False).strip()
        print(f"Current filename:\t {name}")

        # splitting into seperate pages for easier parsing
        # <hr> tag is used consistently in filings for page breaks
        hr_breaks = form.find_all(lambda tag: tag.name == 'hr' and 'page-break-after:always' in tag.get('style', ''))
        # transforming into string objects for regex
        hr_breaks = [str(hr) for hr in hr_breaks]
        form_str = str(form)
        # creating regular expression for splitting pages
        hr_regex = '|'.join(map(re.escape, hr_breaks))
        
        form_pages = re.split(hr_regex, form_str)

        # dates of previous quarters
        quarters = list(self.data.keys())[-3:]

        # multiplier
        multiplier = 1
        
        # getting numerical data
        for index, page in enumerate(form_pages):
            page_soup = BeautifulSoup(page, 'html5lib')

            # operations/income/earnings statement (page)
            if ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                           any(term in tag.get_text(strip = True).lower() for term in ['income', 'operations', 'earnings'])
                           and 'statements' in tag.get_text(strip = True).lower()
                           and 'comprehensive' not in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                           any(term in tag.get_text(strip = True).lower() for term in ['income', 'operations', 'earnings'])
                           and 'statements' in tag.get_text(strip = True).lower()
                           and 'comprehensive' not in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("OIE page found:", index)

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the statement
                table = page_soup.find(lambda tag: tag.name == 'table' and 'width' in tag.get('style', '') and
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 89)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("OIE table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.OIE_TERMS.items():
                        if key in variations: 
                            if term not in data.keys():
                                # sum previous quarters' values
                                total = sum([self.data[date][term] for date in quarters])
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        if term == 'eps':
                                            data[term] = round(value - total, 2)
                                        else:
                                            data[term] = round(value / multiplier) - total
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        if term == 'eps':
                                            data[term] = round(value - total, 2)
                                        else:
                                            data[term] = round(value / multiplier) - total
                                except:
                                    data[term] = None

            # balance sheet (page)
            elif ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                            'balance sheets' in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                            'balance sheets' in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("BS page found")

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the balance sheet
                table = page_soup.find(lambda tag: tag.name == 'table' and 
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 99.5)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("BS table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.BS_TERMS.items():
                        if key in variations: 
                            if term not in data.keys():
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier)
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier)
                                except:
                                    data[term] = None

            # cash flows statement (page)
            elif ((page_soup.find(lambda tag: tag.name == 'div' and 'text-align:center' in tag.get('style', '') and 
                            'cash flows' in tag.get_text(strip = True).lower() and tag.find('table') == None)) or 
                    (page_soup.find(lambda tag: tag.name == 'p' and 'text-align:center' in tag.get('style', '') and 
                            'cash flows' in tag.get_text(strip = True).lower() and tag.find('table') == None))):
                # DEBUGGING
                # print("CF page found")

                # finding the multiplier of the page to make everything in millions
                if page_soup.find(lambda tag: (tag.name == 'div' or tag.name == 'p') and 'text-align:center' in tag.get('style', '')
                               and 'millions' in tag.get_text(strip = True).lower()) == None:
                    multiplier = 1000
                else:
                    multiplier = 1

                # finding the table that holds the statement
                table = page_soup.find(lambda tag: tag.name == 'table' and 
                                  float(tag.get('style', '').split('width:')[1].split(';')[0].strip()[:-1]) > 99.5)
                # checking if a table is found
                if table == None:
                    continue
                # DEBUGGING
                # print("CF table found")
                
                # parsing through rows
                for row in table.find_all('tr'):
                    # getting elements in the row
                    cells = [td.get_text(strip = True).lower() for td in row.find_all('td') 
                             if td.get_text(strip = True) != '$' and td.get_text(strip = True) != '']
                    # at least 2 elements in a row
                    if len(cells) < 2:
                        continue
                    # DEBUGGING
                    # print('Row:', cells)
                    # keyword name
                    key = cells[0]

                    for term, variations in Data.CF_TERMS.items():
                        if key in variations:  
                            if term not in data.keys():
                                total = sum([self.data[date][term] for date in quarters]) if term != 'cash' else 0
                                try:
                                    # the value we are interested in for the term
                                    value = cells[1]
                                    # formatting vaue
                                    if '(' in value:
                                        value = -float(Data.NEGATIVE_PATTERN.sub('', value)) if '.' in value else -int(Data.NEGATIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier) - total
                                    else:
                                        value = float(Data.POSITIVE_PATTERN.sub('', value)) if '.' in value else int(Data.POSITIVE_PATTERN.sub('', value))
                                        data[term] = round(value / multiplier) - total
                                except:
                                    data[term] = None

            # getting M.D.&A. initial page index
            elif (page_soup.find_all(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p') and 
                                     'discussion and analysis of financial condition and results' in tag.get_text(strip = True).lower()
                                     and tag.find('table') == None and 'font-weight' in tag.get('style', '') and index > 1)):
                # DEBUGGING
                # print("Found M.D.&A. initial page index")
                # saving the index
                start_index = index

            # getting M.D.&A. final page index
            elif (page_soup.find_all(lambda tag: (tag.name == 'span' or tag.name == 'font' or tag.name == 'p') and 
                                     'quantitative and qualitative disclosures about market risk' in tag.get_text(strip = True).lower()
                                     and tag.find('table') == None and 'font-weight' in tag.get('style', '') and index > 1)):
                # DEBUGGING
                # print("Found M.D.&A. final page index")
                # saving the index
                end_index = index

            else:
                continue

        return data

    def process_mda(self, pages: list) -> list:
        """Method for processing the 'Management's Discussion and Analysis of Financial Condition
        and Results of Operations' pages. The method will extract 'forward-looking statements' with
        appropriate and important context for sentiment analysis.

        :param pages: The pages that belong to M.D.&A.
        :rtype: List. 
        """
        # initialising list
        important = []

        for page in pages:
            page_soup = BeautifulSoup(page, 'html5lib')
            # getting the source code for all <div> and <p> tags where the [PATTERN] is seen
            paragraphs = [paragraph for paragraph in page_soup.find_all(lambda tag: tag.name == 'div' or tag.name == 'p')
                          if Data.PATTERN.search(paragraph.get_text(strip = False).lower())]

            if len(paragraphs) < 1:
                print("No paragraphs found.")
                continue

            # DEBUGGING
            # print("Paragraphs found.")
            
            # normalizing paragraphs
            normalized = []
            for paragraph in paragraphs:
                # paragraphs with 'italic' style can be disregarded
                if paragraph.name == 'div':
                    italic = False
                    for tag in paragraph.find_all(lambda tag: tag.name == 'font' or tag.name == 'span'):
                        if 'italic' in tag.get('style', ''):
                            italic = True
                            break
                    if italic:
                        continue
                    else:
                        # normalizing text
                        normalized.append(unicodedata.normalize('NFKC', paragraph.get_text(strip = False).lower()).replace('  ', ' '))
                else:
                    if 'italic' in tag.get('style', ''):
                        continue
                    else:
                        # normalizing text
                        normalized.append(unicodedata.normalize('NFKC', paragraph.get_text(strip = False).lower()).replace('  ', ' '))
            # DEBUGGING
            # print("Paragraphs normalized.")
            
            for paragraph in normalized:
                sentences = re.split(r'(?<=[.!?]) +', paragraph)
                text = ""
                for sentence in sentences:
                    # checking if context words appear in sentence
                    if Data.CONTEXT.search(sentence):
                        # DEBUGGING
                        # print("Contextually important sentence found.")
                        text += " " + sentence
                    else:
                        continue
                
                if text != "":
                    important.append(text)

        return important

    def process_filings(self) -> None:
        """Master method for processing filings.
        """
        for idx in range(len(self.metadata)):
        # for idx in range(8):
            if self.metadata.iloc[idx]['form'] == '10-Q':
                quarter = (idx % 4) + 1
                self.data[self.metadata.iloc[idx]['filingDate']] = self.process_quarterly(self.metadata.iloc[idx]['accessionNumber'], quarter)
                
                # continue
            elif self.metadata.iloc[idx]['form'] == '10-K':
                self.data[self.metadata.iloc[idx]['filingDate']] = self.process_annual(self.metadata.iloc[idx]['accessionNumber'])
                # continue
